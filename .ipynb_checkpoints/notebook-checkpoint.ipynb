{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7f4d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/_5vx1kfs0zb1d286dqr8f1zc0000gn/T/ipykernel_25422/2545537586.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"target\"][pd.isnull(df[\"target\"])] = 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import \\\n",
    "    TimeSeriesSplit  # Découper une série temporelle en prenant en compte la dépendance temporelle\n",
    "from sklearn.feature_selection import \\\n",
    "    SequentialFeatureSelector  # Sélectionner de manière séquentielle un sous ensemble de caractéristiques à partie d'un ensemble plus large\n",
    "from sklearn.linear_model import \\\n",
    "    RidgeClassifier  # Fonction linéaire régularisée, prédire la classe d'un échantillon à partir de caractéristiques\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "###################################### TRAITEMENT DE DONNEES ##########################################\n",
    "\n",
    "df = pd.read_csv(\"nba_games.csv\", index_col=0)\n",
    "\n",
    "# → Trier les lignes avec la date et obtenir les nouveaux index ensuite, sans créer une colonne des anciens index\n",
    "df = df.sort_values(\"date\")\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "del df[\"mp.1\"]\n",
    "del df[\"mp_opp.1\"]\n",
    "del df[\"index_opp\"]\n",
    "\n",
    "# team = box scores for one team\n",
    "# add_target => inclue une colonne indiquant le résultat de l'équipe au match d'après\n",
    "def add_target(team):\n",
    "    team[\"target\"] = team[\"won\"].shift(-1)\n",
    "    return team\n",
    "\n",
    "\n",
    "df = df.groupby(\"team\", group_keys=False).apply(add_target)\n",
    "df[\"target\"][pd.isnull(df[\"target\"])] = 2\n",
    "df[\"target\"] = df[\"target\"].astype(int, errors=\"ignore\")\n",
    "\n",
    "team_df = df[df[\"team\"] == \"WAS\"]\n",
    "\n",
    "# Checker toutes les valeurs nulles de notre dataframe : false si c'est not null, true si c'est null\n",
    "nulls = pd.isnull(df).sum()\n",
    "nulls = nulls[nulls > 0]\n",
    "# Sélection des colonnes qui ne sont pas dans nulls grâce à l'opérateur négatif ~\n",
    "valid_columns = df.columns[~df.columns.isin(nulls.index)]\n",
    "# Permet de copier les nouvelles colonnes, les ajouter dans des colonnes existantes peuvent créer des erreurs\n",
    "df = df[valid_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb6568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mp    fg   fga    fg%    3p   3pa    3p%    ft   fta    ft%  ...  \\\n",
      "0     240.0  40.0  80.0  0.500  13.0  34.0  0.382  24.0  28.0  0.857  ...   \n",
      "1     240.0  45.0  99.0  0.455  16.0  45.0  0.356  17.0  23.0  0.739  ...   \n",
      "2     240.0  40.0  94.0  0.426  10.0  40.0  0.250  19.0  25.0  0.760  ...   \n",
      "3     240.0  46.0  82.0  0.561  12.0  35.0  0.343  22.0  28.0  0.786  ...   \n",
      "4     240.0  36.0  86.0  0.419  13.0  30.0  0.433  23.0  32.0  0.719  ...   \n",
      "...     ...   ...   ...    ...   ...   ...    ...   ...   ...    ...  ...   \n",
      "1903  240.0  38.0  78.0  0.487   9.0  29.0  0.310  18.0  23.0  0.783  ...   \n",
      "1904  240.0  36.0  86.0  0.419  10.0  31.0  0.323  20.0  24.0  0.833  ...   \n",
      "1905  240.0  42.0  89.0  0.472  14.0  34.0  0.412  12.0  16.0  0.750  ...   \n",
      "1906  240.0  42.0  84.0  0.500  20.0  47.0  0.426  21.0  25.0  0.840  ...   \n",
      "1907  240.0  46.0  86.0  0.535  10.0  26.0  0.385  15.0  19.0  0.789  ...   \n",
      "\n",
      "      tov%_max_opp  usg%_max_opp  ortg_max_opp  drtg_max_opp  team_opp  \\\n",
      "0             22.5          35.0         233.0         125.0       BOS   \n",
      "1             40.0          35.5         300.0         119.0       LAL   \n",
      "2             40.0          34.5         177.0         102.0       GSW   \n",
      "3             28.6          33.9         165.0         136.0       PHI   \n",
      "4             50.0          45.1         170.0         119.0       CLE   \n",
      "...            ...           ...           ...           ...       ...   \n",
      "1903          22.2          27.0         150.0         108.0       OKC   \n",
      "1904          23.8          31.5         148.0         113.0       MIN   \n",
      "1905          25.4          45.4         139.0         122.0       LAL   \n",
      "1906          23.7          35.4         154.0         151.0       CHI   \n",
      "1907          31.1          28.1         125.0         126.0       CHO   \n",
      "\n",
      "      total_opp  home_opp        date    won  target  \n",
      "0           126         1  2022-10-18  False       0  \n",
      "1           109         0  2022-10-18   True       0  \n",
      "2           123         1  2022-10-18  False       0  \n",
      "3           117         0  2022-10-18   True       1  \n",
      "4           105         0  2022-10-19   True       0  \n",
      "...         ...       ...         ...    ...     ...  \n",
      "1903        130         1  2023-03-03  False       2  \n",
      "1904        110         0  2023-03-03  False       2  \n",
      "1905        102         1  2023-03-03   True       2  \n",
      "1906        104         1  2023-03-03   True       2  \n",
      "1907        106         1  2023-03-03   True       2  \n",
      "\n",
      "[1908 rows x 141 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/_5vx1kfs0zb1d286dqr8f1zc0000gn/T/ipykernel_25422/3944225314.py:45: FutureWarning: Dropping of nuisance columns in rolling operations is deprecated; in a future version this will raise TypeError. Select only valid columns before calling the operation. Dropped columns were Index(['team'], dtype='object')\n",
      "  rolling = team.rolling(30).mean()\n"
     ]
    }
   ],
   "source": [
    "##################################################### MACHINE LEARNING #################################################################\n",
    "\n",
    "# Traiter un grand nombre de colonnes en machine learning peut entraîner des erreurs de corrélations, utilisation de sélecteurs\n",
    "# Machine learning model\n",
    "rr = RidgeClassifier(alpha=1)  # Alpha pour la régularisation\n",
    "split = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Le sélecteur va entraîner la machine en envoyant des parties de features et récupérer les features les plus pertinentes\n",
    "sfs = SequentialFeatureSelector(rr, n_features_to_select=30, direction=\"forward\", cv=split)\n",
    "\n",
    "removed_columns = [\"season\", \"date\", \"won\", \"target\", \"team\", \"team_opp\"]\n",
    "\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]\n",
    "# Valeurs des colonnes sélectionnées sont entre 0 et 1\n",
    "scaler = MinMaxScaler()\n",
    "df[selected_columns] = scaler.fit_transform(df[selected_columns])\n",
    "\n",
    "# Récupérer les 30 meilleures features pour prédire\n",
    "sfs.fit(df[selected_columns], df[\"target\"])\n",
    "\n",
    "# sfs.get_support => True: colonnes pertinentes pour notre prédiction\n",
    "predictors = list(selected_columns[sfs.get_support()])\n",
    "\n",
    "def backtest(data, model, predictors, date):\n",
    "    all_predictions = []\n",
    "\n",
    "    train = data[data[\"date\"] < date]\n",
    "    model.fit(train[predictors], train[\"target\"])\n",
    "    test = data[data[\"date\"] == date]\n",
    "\n",
    "    preds = model.predict(test[predictors])\n",
    "    preds = pd.Series(preds, index=test.index)\n",
    "\n",
    "    combined = pd.concat([test[\"target\"], preds], axis=1)\n",
    "    combined.columns = [\"actual\", \"prediction\"]\n",
    "\n",
    "    all_predictions.append(combined)\n",
    "    return pd.concat(all_predictions)\n",
    "\n",
    "# Récupérer les colonnes sélectionnées et ajouter les colonnes won et team\n",
    "df_rolling = df[list(selected_columns) + [\"won\", \"team\"]]\n",
    "\n",
    "# Groupe les 10 dernières lignes d'une équipe de notre df, pour chacune des lignes, retourne la moyenne avec mean\n",
    "def find_team_averages(team):\n",
    "    rolling = team.rolling(30).mean()\n",
    "    return rolling\n",
    "# Regrouper nos colonnes pour une équipe spécifique\n",
    "df_rolling = df_rolling.groupby([\"team\"], group_keys = False).apply(find_team_averages)\n",
    "\n",
    "rolling_cols = [f\"{col}_10\" for col in df_rolling.columns]\n",
    "df_rolling.columns = rolling_cols\n",
    "\n",
    "df = pd.concat([df, df_rolling], axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "def shift_col(team, col_name):\n",
    "    next_col = team[col_name].shift(-1)\n",
    "    return next_col\n",
    "\n",
    "def add_col(df, col_name):\n",
    "    return df.groupby(\"team\", group_keys=False).apply(lambda x: shift_col(x, col_name))\n",
    "\n",
    "df[\"home_next\"] = add_col(df, \"home\")\n",
    "df[\"team_opp_next\"] = add_col(df, \"team_opp\")\n",
    "df[\"date_next\"] = add_col(df, \"date\")\n",
    "df = df.copy()\n",
    "\n",
    "full = df.merge(df[rolling_cols + [\"team_opp_next\", \"date_next\", \"team\"]],\n",
    "                left_on=[\"team\", \"date_next\"],\n",
    "                right_on=[\"team_opp_next\", \"date_next\"]\n",
    ")\n",
    "\n",
    "removed_columns = list(full.columns[full.dtypes == \"object\"]) + removed_columns\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]\n",
    "\n",
    "sfs.fit(full[selected_columns], full[\"target\"])\n",
    "predictions = backtest(full, rr, predictors, \"2023-03-01\")\n",
    "accuracy = accuracy_score(predictions[\"actual\"], predictions[\"prediction\"])\n",
    "full = pd.concat([full, predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d1057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
